{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pdf(data):\n",
    "    from scipy.stats.kde import gaussian_kde\n",
    "    from numpy import linspace\n",
    "    \n",
    "    kde = gaussian_kde(data)\n",
    "\n",
    "    return kde    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pdf(data, label='', x_axis=''):\n",
    "    from scipy.stats.kde import gaussian_kde\n",
    "    from numpy import linspace\n",
    "    \n",
    "    # create two subplots\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.suptitle(\"Probability Distribution and Historgram \"+label)\n",
    "    \n",
    "    #create the kernel, which estimates the probability over the values in the array\n",
    "    kde = gaussian_kde(data)\n",
    "    \n",
    "    #these are the values over wich your kernel will be evaluated\n",
    "    dist_space = linspace(min(data),max(data), 100)\n",
    "\n",
    "    # plot the results\n",
    "    axs[0].plot(dist_space, kde(dist_space))\n",
    "    axs[0].set_ylabel('probability')\n",
    "    axs[0].set_xlabel(x_axis)\n",
    "    axs[1].hist(data)\n",
    "    axs[1].set_ylabel('histogram')\n",
    "    axs[1].set_xlabel('x_axis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist(df, var='age', bucket_size=5, to_print=False):\n",
    "    import math\n",
    "    \n",
    "    # create an array that holds the counts of different age groups in bucket_size \n",
    "    arr = [];\n",
    "    for x in range(0,100,bucket_size):\n",
    "        arr.append(0)\n",
    "    \n",
    "    # go through the data, look at each age and update counter for that age group\n",
    "    for x in df[var]:\n",
    "        index = math.floor(x/bucket_size)\n",
    "        arr[index] = arr[index] + 1;\n",
    "\n",
    "    if to_print:\n",
    "        age = 0;\n",
    "        # print the array\n",
    "        for x in arr:\n",
    "            print(str(age) + \"-\" + str(age+bucket_size), \": \", x)\n",
    "            age = age + bucket_size\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_new_len(len_df_one, dist_one, len_df_two, dist_two):\n",
    "    import math \n",
    "    \n",
    "    new_len = len_df_one\n",
    "\n",
    "    for precision in np.arange(1, 0, -0.05):\n",
    "        new_len = len_df_one\n",
    "        for i in range(len(dist_one)):\n",
    "            if dist_one[i] < (new_len*dist_two[i]/len_df_two)*precision:\n",
    "                if dist_one[i] != 0:\n",
    "                    new_len = math.floor(dist_one[i]*len_df_two/dist_two[i])\n",
    "                else:\n",
    "                    new_len = new_len - (new_len*dist_two[i]/len_df_two)\n",
    "        if new_len >= 50:\n",
    "            print(\"New Length: \", new_len, \" with Precision: \", precision)\n",
    "            break\n",
    "            \n",
    "    return new_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_dist(df_to, df_from, var='age', var_1 = 'subject', bucket_size=3, new_len=None):\n",
    "    import math \n",
    "    \n",
    "    df_new = pd.DataFrame([])\n",
    "    \n",
    "    # sort the dataframes\n",
    "    df_to = df_to.sort_values(by=var)\n",
    "    df_from = df_from.sort_values(by=var)\n",
    "    \n",
    "    # get the distributions from both\n",
    "    dist_to = get_dist(df_to, bucket_size=bucket_size)\n",
    "    dist_from = get_dist(df_from, bucket_size=bucket_size)\n",
    "    \n",
    "    index = 0\n",
    "    i = 0\n",
    "    rand_subj = []\n",
    "    \n",
    "    if new_len:\n",
    "        df_new_length = new_len\n",
    "    else:\n",
    "        # calculate the size of the new dataset that would allow for the same distribution as the dataset being mimicked\n",
    "        df_new_length = find_new_len(len(df_to), dist_to, len(df_from), dist_from)\n",
    "    \n",
    "    # go through the number of subjects in the age range of the resampling data\n",
    "    for x in np.arange(0, 100, bucket_size):\n",
    "        subj_bucket = []\n",
    "        \n",
    "        # get all the subjects in the age range of the resampling data\n",
    "        for j in range(dist_to[i]):\n",
    "            subj_bucket.append((df_to[var_1])[index+j])\n",
    "        \n",
    "        index = index + dist_to[i]\n",
    "        \n",
    "        # get the number of subjects in the data that is being mimicked\n",
    "        num_rand = math.floor(df_new_length * (dist_from[i]/len(df_from)))\n",
    "        #print(len(subj_bucket), num_rand)\n",
    "        \n",
    "        if not len(subj_bucket) == 0:\n",
    "            # choose random subjects from subject bucket\n",
    "            # the number of random subjects chosen depends on the distributions\n",
    "            rand_subj = []\n",
    "            \n",
    "            if dist_to[i] < num_rand:\n",
    "                rand_subj = np.random.choice(subj_bucket, size=dist_to[i], replace=False)\n",
    "            else:\n",
    "                rand_subj = np.random.choice(subj_bucket, size=num_rand, replace=False)\n",
    "        \n",
    "        for sub in rand_subj:\n",
    "                temp = pd.DataFrame(df_to[df_to[var_1] == sub])\n",
    "                df_new = pd.concat([df_new, df_to[df_to[var_1] == sub]])\n",
    "\n",
    "        # increment index for age distribution array\n",
    "        i = i+1\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(df_to, df_from, title_to='', title_from='', var='age', var_1='subject', bucket_size=3, new_len = None):\n",
    "    from scipy import stats\n",
    "\n",
    "    plot_pdf(df_from[var], title_from, var)\n",
    "    plot_pdf(df_to[var], title_to , var)\n",
    "    \n",
    "    # sample from original\n",
    "    df_sample = match_dist(df_to, df_from, bucket_size = bucket_size, new_len = new_len)\n",
    "    print(\"Actual Length: \", len(df_sample))\n",
    "    print(df_sample.head())\n",
    "    \n",
    "    # plot new probability density function\n",
    "    plot_pdf(df_sample[var], title_to + \":\" + title_from, var)\n",
    "    \n",
    "    # test if the two distributions would be the same\n",
    "    print(\"stats: \", stats.ks_2samp(df_sample[var], df_from[var]))\n",
    "    \n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question:\n",
    "If the distribution of ages in training and test sets is causing the poor generalizability of both complex and simple models, then both simple and complex models trained on datasets with similar age distributions to our original training dataset will perform worse than chance when tested on samples from new datasets that mimic the age distribution of our original test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# project directory\n",
    "project_dir = Path('/data/NNDSP')\n",
    "\n",
    "# NNDSP data directories\n",
    "nndsp_bids_dir = Path('/data/NNDSP/bids_2017_07_14_generic')\n",
    "nndsp_fs_dir = Path('/data/NNDSP/derivatives/fs5.3_subj')\n",
    "nndsp_bar_dir = Path('/data/NNDSP/derivatives/bar_subj')\n",
    "nndsp_pheno_file = Path('/data/NNDSP/anal/analysis_notebooks/phenotype_files/NNDSP_famid.csv')\n",
    "\n",
    "# HCP data directories\n",
    "hcp_bids_dir = Path('/data/HCP/HCP_900/s3/hcp')\n",
    "hcp_fs_dir = Path('/data/NNDSP/derivatives/fs_hcp_subj')\n",
    "hcp_bar_dir = Path('/data/NNDSP/derivatives/bar_hcp_subj')\n",
    "hcp_pheno_file = Path('/data/NNDSP/nino/HCP_ages.csv')\n",
    "\n",
    "# NKI data directories\n",
    "nki_bids_dir = Path('/data/NNDSP/anal/NKI')\n",
    "nki_fs_dir = Path('/data/NNDSP/derivatives/fs_nki_subj')\n",
    "nki_bar_dir = Path('/data/NNDSP/derivatives/bar_nki_subj')\n",
    "nki_pheno_file = Path('/data/NNDSP/anal/analysis_notebooks/phenotype_files/participants.tsv')\n",
    "\n",
    "# CoRR data directories\n",
    "corr_bids_dir = Path('/data/DSST/CoRR/bids_corr')\n",
    "corr_fs_dir = Path('/data/DSST/CoRR/fs_corr')\n",
    "corr_bar_dir = Path('/data/DSST/CoRR/bar_corr')\n",
    "corr_pheno_file = Path('/data/DSST/CoRR/phenotype_files/corr_ages.csv')\n",
    "\n",
    "# SALD data directories\n",
    "sald_bids_dir = Path('/data/DSST/SALD/bids_sald')\n",
    "sald_fs_dir = Path('/data/DSST/SALD/fs_sald')\n",
    "sald_bar_dir = Path('/data/DSST/SALD/bar_sald/baracus')\n",
    "sald_pheno_file = Path('/data/DSST/SALD/phenotype_files/sub_information.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNDSP Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the subjects that we have fs and add subject number\n",
    "df_nndsp = pd.DataFrame({'subj_paths' : [x.as_posix() for x in nndsp_fs_dir.glob('sub-*')]})\n",
    "df_nndsp = df_nndsp.assign(MASKID = [int(Path(x).name[4:]) for x in df_nndsp.subj_paths])\n",
    "df_nndsp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the subjects we have fs of with their ages\n",
    "df_nndsp = pd.merge(df_nndsp, pd.read_csv(nndsp_pheno_file.as_posix()), on='MASKID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns so that we have standardization across datasets\n",
    "df_nndsp = df_nndsp.rename(index=str, columns = {'MASKID' : 'subject', 'age_at_scan' : 'age'})\n",
    "df_nndsp = df_nndsp.drop_duplicates(subset='subject', keep='first')\n",
    "df_nndsp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HCP Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the subjects that we have fs and add subject number\n",
    "df_hcp = pd.DataFrame({'subj_paths' : [x.as_posix() for x in hcp_fs_dir.glob('sub-*')]})\n",
    "df_hcp = df_hcp.assign(Subject = [int(Path(x).name[4:]) for x in df_hcp.subj_paths])\n",
    "df_hcp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the subjects we have fs of with their ages\n",
    "df_hcp = pd.merge(df_hcp, pd.read_csv(hcp_pheno_file.as_posix()), on='Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns so that we have standardization across datasets\n",
    "df_hcp = df_hcp.rename(index=str, columns={'Subject' : 'subject', 'Age_in_Yrs' : 'age'})\n",
    "df_hcp = df_hcp.drop_duplicates(subset='subject', keep='first')\n",
    "df_hcp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NKI Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the subjects that we have fs and add subject number\n",
    "df_nki = pd.DataFrame({'subj_paths' : [x.as_posix() for x in nki_fs_dir.glob('sub-*')]})\n",
    "df_nki = df_nki.assign(participant_id = [Path(x).name[4:13] for x in df_nki.subj_paths])\n",
    "df_nki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the subjects that we have fs with age\n",
    "df_nki = pd.merge(df_nki, pd.read_csv(nki_pheno_file.as_posix(), sep='\\t'), on='participant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename so that we have standardization across datasets\n",
    "df_nki = df_nki.rename(index=str, columns={'participant_id' : 'subject', 'age' : 'age'})\n",
    "df_nki = df_nki.drop_duplicates(subset='subject', keep='first')\n",
    "df_nki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoRR Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the subjects that we have fs and add subject number\n",
    "df_corr = pd.DataFrame({'subj_paths' : [x.as_posix() for x in corr_fs_dir.glob('sub-*')]})\n",
    "df_corr = df_corr.assign(SUBID = [int(Path(x).name[4:11]) for x in df_corr.subj_paths])\n",
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge subjects with ages \n",
    "df_corr = pd.merge(df_corr, pd.read_csv(corr_pheno_file.as_posix()), on='SUBID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename so that we have standardization across datasets\n",
    "df_corr = df_corr.rename(index=str, columns={'SUBID' : 'subject', 'AGE_AT_SCAN_1' : 'age'})\n",
    "df_corr = df_corr.sort_values(by='subj_paths')\n",
    "df_corr = df_corr.drop_duplicates(subset='subject', keep='first')\n",
    "df_corr.age = pd.to_numeric(df_corr.age, errors='coerce').fillna(0).astype(np.int64)\n",
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALD Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete once we have SALD FS files\n",
    "df_sald = pd.DataFrame({'subj_paths': [x.as_posix() for x in sald_fs_dir.glob('sub-*')]})\n",
    "df_sald = df_sald.assign(Sub_ID = [int(Path(x).name[4:]) for x in df_sald.subj_paths])\n",
    "df_sald.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge phenotype file with dataframe\n",
    "df_sald = pd.merge(df_sald, pd.read_excel(sald_pheno_file.as_posix()), on='Sub_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sald = df_sald.rename(index = str, columns = {'Sub_ID': 'subject', 'Age': 'age'})\n",
    "df_sald = df_sald.sort_values(by='subject')\n",
    "df_sald = df_sald.drop_duplicates(subset='subject', keep='first')\n",
    "df_sald.age = pd.to_numeric(df_sald.age, errors='coerce').fillna(0).astype(np.int64)\n",
    "df_sald.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample NKI:NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nki_nndsp = sample(df_nki, df_nndsp, title_to='NKI', title_from='NNDSP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample CoRR:NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_nndsp = sample(df_corr, df_nndsp, title_to='CoRR', title_from='NNDSP', bucket_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample SALD:NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sald_nndsp = sample(df_sald, df_nndsp, title_to='SALD', title_from='NNDSP', bucket_size=10, new_len=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample NKI:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nki_hcp = sample(df_nki, df_hcp, title_to='NKI', title_from='HCP', bucket_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample CoRR:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_hcp = sample(df_corr, df_hcp, title_to='CoRR', title_from='HCP', bucket_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample SALD:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sald_hcp = sample(df_sald, df_hcp, title_to='SALD', title_from='HCP', bucket_size=2, new_len=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /data/NNDSP/anal/analysis_notebooks/follow_up_analysis/util_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hcp_mae = {}\n",
    "nki2hcp_mae = {}\n",
    "corr2hcp_mae = {}\n",
    "sald2hcp_mae = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nndsp, nndsp_complex_train, nndsp_complex_test, nndsp_complex_pipes = complex_model(df_nndsp, nndsp_bar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndsp_simple_train, nndsp_simple_test, nndsp_simple_pipe = simple_model(df_nndsp, nndsp_bar_dir, \n",
    "                                                                        model=True, \n",
    "                                                                        model_train = nndsp_complex_train, \n",
    "                                                                        model_test=nndsp_complex_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_mae['Complex on NNDSP'] = complex_test(df_hcp, hcp_bar_dir, nndsp_complex_pipes, data='HCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_mae['Simple on NNDSP'] = simple_test(df_hcp, hcp_bar_dir, nndsp_simple_pipe, data='HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on NKI:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nk2hcp_mae['Complex on NNDSP'] = complex_test(df_nki_hcp, nki_bar_dir, nndsp_complex_pipes, data='NKI:HCP', is_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nki2hcp_mae['Simple on NNDSP'] = simple_test(df_nki_hcp, nki_bar_dir, nndsp_simple_pipe, data='NKI:HCP', is_int=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CORRS:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr2hcp_mae['Complex on NNDSP'] complex_test(df_nki_hcp, nki_bar_dir, nndsp_complex_pipes, data='NKI:HCP', is_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr2hcp_mae['Simple on NNDSP] simple_test(df_nki_hcp, nki_bar_dir, nndsp_simple_pipe, data='NKI:HCP', is_int=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on SALD:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sald2hcp_mar['Complex on NNDSP'] = complex_test(df_sald_hcp.drop_duplicates(), sald_bar_dir, nndsp_complex_pipes, data='SALD:HCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal2hcp_mae['Simple on NNDSP'] = simple_test(df_sald_hcp, sald_bar_dir, nndsp_simple_pipe, data='SALD:HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NKI:NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nki_nndsp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nki2nndsp, nki2nndsp_complex_train, nki2nndsp_complex_test, nki2nndsp_complex_pipes = complex_model(df_nki_nndsp, \n",
    "                                                                                                           nki_bar_dir, \n",
    "                                                                                                           is_int = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nki2nndsp_simple_train, nki2nndsp_simple_test, nki2nndsp_simple_pipe = simple_model(df_nki_nndsp, nki_bar_dir, \n",
    "                                                                        model=True, \n",
    "                                                                        model_train = nki2nndsp_complex_train, \n",
    "                                                                        model_test=nki2nndsp_complex_test,\n",
    "                                                                                   is_int=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_mae['Complex on NKI:NNDSP'] = complex_test(df_hcp, hcp_bar_dir, nki2nndsp_complex_pipes, data='HCP', is_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_mae['Simple on NKI:NNDSP'] = simple_test(df_hcp, hcp_bar_dir, nki2nndsp_simple_pipe, data='HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on CoRR:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr2hcp_mae['Complex on NKI:NNDSP'] = complex_test(df_corr_hcp, corr_bar_dir, nki2nndsp_complex_pipes, data='CoRR:HCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr2hcp_mae['Simple on NKI:NNDSP'] = simple_test(df_corr_hcp, corr_bar_dir, nki2nndsp_simple_pipe, data='CoRR:HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on SALD:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sald2hcp_mae['Complex on NKI:NNDSP'] = complex_test(df_sald_hcp, sald_bar_dir, nki2nndsp_complex_pipes, data='SALD:HCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sald2hcp_mae['Simple on NKI:NNDSP'] = simple_test(df_sald_hcp, sald_bar_dir, nki2nndsp_simple_pipe, data='SALD:HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on CoRR:NNDSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores_corr2nndsp, corr2nndsp_complex_train, corr2nndsp_complex_test, corr2nndsp_complex_pipes = complex_model(df_corr_nndsp, \n",
    "#                                                                                                            corr_bar_dir, \n",
    "#                                                                                                            is_int = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corr2nndsp_simple_train, corr2nndsp_simple_test, corr2nndsp_simple_pipe = simple_model(df_corr_nndsp, corr_bar_dir, \n",
    "#                                                                         model=True, \n",
    "#                                                                         model_train = corr2nndsp_complex_train, \n",
    "#                                                                         model_test=corr2nndsp_complex_test,\n",
    "#                                                                                    is_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hcp_mae['Complex on CoRR:NNDSP'] = complex_test(df_hcp, hcp_bar_dir, corr2nndsp_complex_pipes, data='HCP', is_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hcp_mae['Simple on CoRR:NNDSP'] = simple_test(df_hcp, hcp_bar_dir, corr2nndsp_simple_pipe, data='HCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on NKI:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nki2hcp_mae['Complex on CoRR:NNDSP'] = complex_test(df_nki_hcp, nki_bar_dir, corr2nndsp_complex_pipes, data='NKI:HCP', is_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nki2hcp_mae['Simple on CoRR:NNDSP'] = simple_test(df_nki_hcp, nki_bar_dir, corr2nndsp_simple_pipe, data='NKI:HCP', is_int = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on SALD:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sald2hcp_mae['Complex on CoRR:NNDSP'] = complex_test(df_sald_hcp, sald_bar_dir, corr2nndsp_complex_pipes, data='SALD:HCP', is_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sald2hcp_mae['Simple on CoRR:NNDSP'] = simple_test(df_sald_hcp, sald_bar_dir, corr2nndsp_simple_pipe, data='SALD:HCP', is_int = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /data/NNDSP/anal/analysis_notebooks/follow_up_analysis/util_stats.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hcp_rand_ages = random_ages(df_hcp)\n",
    "plot_rand_hist(hcp_rand_ages, hcp_mae, title='HCP',\n",
    "              set_context='notebook', fig_tuple=(10, 7), legend=True)\n",
    "get_percentile(hcp_rand_ages, hcp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NKI:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nki2hcp_rand_ages = random_ages(df_nki_hcp)\n",
    "plot_rand_hist(nki2hcp_rand_ages, nki2hcp_mae, title='NKI:HCP',\n",
    "              set_context='notebook', fig_tuple=(10, 7), legend=True)\n",
    "get_percentile(nki2hcp_rand_ages, nki2hcp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CoRR:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr2hcp_rand_ages = random_ages(df_corr_hcp)\n",
    "plot_rand_hist(corr2hcp_rand_ages, corr2hcp_mae, title='CoRR:HCP',\n",
    "              set_context='notebook', fig_tuple=(10, 7), legend=True)\n",
    "get_percentile(corr2hcp_rand_ages, corr2hcp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALD:HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sald2hcp_rand_ages = random_ages(df_sald_hcp)\n",
    "plot_rand_hist(sald2hcp_rand_ages, sald2hcp_mae, title='SALD:HCP',\n",
    "              set_context='notebook', fig_tuple=(10, 7), legend=True)\n",
    "get_percentile(sald2hcp_rand_ages, sald2hcp_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "561px",
    "left": "1px",
    "right": "20px",
    "top": "107px",
    "width": "216px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
