{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNDSP Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nndsp_subjectdata(nndsp_fs_dir, nndsp_pheno_file):\n",
    "    # merge the subjects that we have fs and add subject number\n",
    "    df_nndsp = pd.DataFrame({'subj_paths' : [x.as_posix() for x in nndsp_fs_dir.glob('sub-*')]})\n",
    "    df_nndsp = df_nndsp.assign(MASKID = [int(Path(x).name[4:]) for x in df_nndsp.subj_paths])\n",
    "    \n",
    "    # merge the subjects we have fs of with their ages\n",
    "    df_nndsp = pd.merge(df_nndsp, pd.read_csv(nndsp_pheno_file.as_posix()), on='MASKID')\n",
    "\n",
    "    # rename columns so that we have standardization across datasets\n",
    "    df_nndsp = df_nndsp.rename(index=str, columns = {'MASKID' : 'subject', 'age_at_scan' : 'age', 'Sex': 'sex'})\n",
    "    df_nndsp['sex'] = [2 if s == 'Male' else 1 for s in df_nndsp.sex]\n",
    "    \n",
    "    df_nndsp = df_nndsp.drop_duplicates(subset='subject', keep='first')\n",
    "    df_nndsp = df_nndsp.sort_values(by='subject')\n",
    "    \n",
    "    return df_nndsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HCP Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hcp_subjectdata(hcp_fs_dir, hcp_pheno_file, hcp_pheno2_file):\n",
    "    # merge the subjects that we have fs and add subject number\n",
    "    df_hcp = pd.DataFrame({'subj_paths' : [x.as_posix() for x in hcp_fs_dir.glob('sub-*')]})\n",
    "    df_hcp = df_hcp.assign(Subject = [int(Path(x).name[4:]) for x in df_hcp.subj_paths])\n",
    "    \n",
    "    # merge the subjects we have fs of with their ages\n",
    "    df_hcp = pd.merge(df_hcp, pd.read_csv(hcp_pheno_file.as_posix()), on='Subject')\n",
    "    df_hcp = pd.merge(df_hcp, pd.read_csv(hcp_pheno2_file.as_posix())[['Subject', 'Gender']], on = 'Subject')\n",
    "    df_hcp['Gender'] = [2 if s == 'M' else 1 for s in df_hcp.Gender]\n",
    "    \n",
    "    # rename columns so that we have standardization across datasets\n",
    "    df_hcp = df_hcp.rename(index=str, columns={'Subject' : 'subject', 'Age_in_Yrs' : 'age', 'Gender': 'sex'})\n",
    "    df_hcp = df_hcp.drop_duplicates(subset='subject', keep='first')\n",
    "    df_hcp = df_hcp.sort_values(by='subject')\n",
    "    return df_hcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NKI Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nki_subjectdata(nki_fs_dir, nki_pheno_file):\n",
    "    # merge the subjects that we have fs and add subject number\n",
    "    df_nki = pd.DataFrame({'subj_paths' : [x.as_posix() for x in nki_fs_dir.glob('sub-*')]})\n",
    "    df_nki = df_nki.assign(participant_id = [Path(x).name[4:13] for x in df_nki.subj_paths])\n",
    "    \n",
    "    # merge the subjects that we have fs with age\n",
    "    df_nki = pd.merge(df_nki, pd.read_csv(nki_pheno_file.as_posix(), sep='\\t'), on='participant_id')\n",
    "    df_nki['sex'] = [2 if s == 'MALE' else 1 for s in df_nki.sex]\n",
    "    \n",
    "    # rename so that we have standardization across datasets\n",
    "    df_nki = df_nki.rename(index=str, columns={'participant_id' : 'subject', 'age' : 'age'})\n",
    "    df_nki = df_nki.drop_duplicates(subset='subject', keep='first')\n",
    "    df_nki = df_nki.sort_values(by='subject')\n",
    "    return df_nki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoRR Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_subjectdata(corr_fs_dir, corr_pheno_file):\n",
    "    # merge the subjects that we have fs and add subject number\n",
    "    df_corr = pd.DataFrame({'subj_paths' : [x.as_posix() for x in corr_fs_dir.glob('sub-*')]})\n",
    "    df_corr = df_corr.assign(SUBID = [int(Path(x).name[4:11]) for x in df_corr.subj_paths])\n",
    "    \n",
    "    # merge subjects with ages \n",
    "    df_corr = pd.merge(df_corr, pd.read_csv(corr_pheno_file.as_posix()), on='SUBID')\n",
    "    \n",
    "    # rename so that we have standardization across datasets\n",
    "    df_corr = df_corr.rename(index=str, columns={'SUBID' : 'subject', 'AGE_AT_SCAN_1' : 'age', 'SEX': 'sex'})\n",
    "    df_corr.sex = [1 if s == '1' else 2 for s in df_corr.sex]\n",
    "    \n",
    "    df_corr = df_corr.sort_values(by='subj_paths')\n",
    "    df_corr = df_corr.drop_duplicates(subset='subject', keep='first')\n",
    "    df_corr.age = pd.to_numeric(df_corr.age, errors='coerce').fillna(0).astype(np.int64)\n",
    "    df_corr = df_corr.sort_values(by='subject')\n",
    "    \n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALD Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sald_subjectdata(sald_fs_dir, sald_pheno_file):\n",
    "    # complete once we have SALD FS files\n",
    "    df_sald = pd.DataFrame({'subj_paths': [x.as_posix() for x in sald_fs_dir.glob('sub-*')]})\n",
    "    df_sald = df_sald.assign(Sub_ID = [int(Path(x).name[4:]) for x in df_sald.subj_paths])\n",
    "    \n",
    "    # merge phenotype file with dataframe\n",
    "    df_sald = pd.merge(df_sald, pd.read_excel(sald_pheno_file.as_posix()), on='Sub_ID')\n",
    "    \n",
    "    df_sald = df_sald.rename(index = str, columns = {'Sub_ID': 'subject', 'Age': 'age', 'Sex.1': 'sex'})\n",
    "    df_sald['sex'] = [1 if s == 1 else 2 for s in df_sald.sex]\n",
    "    \n",
    "    df_sald = df_sald.sort_values(by='subject')\n",
    "    df_sald = df_sald.drop_duplicates(subset='subject', keep='first')\n",
    "    df_sald.age = pd.to_numeric(df_sald.age, errors='coerce').fillna(0).astype(np.int64)\n",
    "    df_sald = df_sald.sort_values(by='subject')\n",
    "    \n",
    "    return df_sald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRIQC Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mriqc_df(mriqc_dir, pheno_file, data = None, data_class = None, merge_df = None):\n",
    "    \n",
    "    df = pd.read_csv(mriqc_dir.joinpath('T1w.csv').as_posix())\n",
    "    \n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        print(\"True\")\n",
    "        del df['Unnamed: 0']\n",
    "    \n",
    "    df = df.assign(dataset = [data for x in range(0, len(df))])\n",
    "    df = df.assign(data_class = [data_class for x in range(0, len(df))])\n",
    "    df = df.rename(index = str, columns = {'subject_id': 'subject'})\n",
    "    \n",
    "    if merge_df is not None:\n",
    "        df = pd.merge(df, merge_df, on='subject')\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
